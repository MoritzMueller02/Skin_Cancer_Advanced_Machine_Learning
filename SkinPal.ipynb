{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f9f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ein Unterverzeichnis oder eine Datei mit dem Namen \"saved_models\" existiert bereits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\morit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\morit\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from geopy) (2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\morit\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Did that so i creates a saved_models folder\n",
    "!mkdir saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0bdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/app.py\n",
    "import os\n",
    "import streamlit as st\n",
    "from PIL import Image, ImageEnhance\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForImageClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    pipeline,\n",
    "    Qwen2VLForConditionalGeneration, Qwen2VLProcessor,\n",
    ")\n",
    "import requests\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from streamlit_folium import st_folium\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "st.set_page_config(page_title=\"Skin Cancer Dashboard\", layout=\"wide\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure you have set your Hugging Face token as an environment variable:\n",
    "# export HF_TOKEN=\"YOUR_TOKEN_HERE\"\n",
    "MODEL_NAME = \"Anwarkh1/Skin_Cancer-Image_Classification\"\n",
    "LLM_NAME = \"google/flan-t5-large\"\n",
    "HF_TOKEN   = \"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\"\n",
    "DATA_DIR = \"data/harvard_dataset\"  # Path where you download and unpack the Harvard Dataverse dataset\n",
    "DIARY_CSV = \"diary.csv\"\n",
    "gemini_api_secret_name = 'AIzaSyDA3nwO6265GZCDaBqTxTAmKWwrSCfSqnc'\n",
    "CANCER_DIR = r\"D:\\Models\\googleflan-t5-xl\" #you \n",
    "LLM_DIR = r\"D:\\Models\\SkinCancer\"\n",
    "\n",
    "# Initialize session state defaults\n",
    "if 'initialized' not in st.session_state:\n",
    "    st.session_state['label'] = None\n",
    "    st.session_state['score'] = None\n",
    "    st.session_state['mole_id'] = ''\n",
    "    st.session_state['geo_location'] = ''\n",
    "    st.session_state['chat_history'] = []\n",
    "    st.session_state['initialized'] = True\n",
    "\n",
    "# Initialize geolocator for free geocoding\n",
    "geolocator = Nominatim(user_agent=\"skin-dashboard\", timeout = 10)\n",
    "\n",
    "# --- Load Model & Feature Extractor ---\n",
    "@st.cache_resource\n",
    "def load_image_model(token: str):\n",
    "    extractor = AutoFeatureExtractor.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        model_dir = LLM_DIR,\n",
    "        use_auth_token=token\n",
    "    )\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        use_auth_token=token\n",
    "    )\n",
    "    return pipeline(\n",
    "        \"image-classification\",\n",
    "        model=model,\n",
    "        feature_extractor=extractor,\n",
    "        device=0  # set to GPU index or -1 for CPU\n",
    "    )\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def load_llm(token: str):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        LLM_NAME,\n",
    "        model_dir = CANCER_DIR,\n",
    "        use_auth_token=token\n",
    "    )\n",
    "    # Use Seq2SeqLM for T5-style (text2text) models:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        LLM_NAME,\n",
    "        use_auth_token=token,\n",
    "    )\n",
    "    return pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=\"auto\",    # or device=0 for single GPU / -1 for CPU\n",
    "        max_length=10000,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "\n",
    "    )\n",
    "\n",
    "# Load the Gemini model\n",
    "classifier = load_image_model(HF_TOKEN) if HF_TOKEN else None\n",
    "explainer = load_llm(HF_TOKEN) if HF_TOKEN else None\n",
    "\n",
    "\n",
    "# --- Diary Init ----\n",
    "\n",
    "def save_entry(img_path: str, mole_id: str, geo_location: str,\n",
    "               label: str, score: float,\n",
    "               body_location: str, prior_consult: str, pain: str, itch: str):\n",
    "    # Ensure that the DataFrame is being read correctly and entry is saved\n",
    "    if not os.path.exists(DIARY_CSV):\n",
    "        df = pd.DataFrame(columns=[\"timestamp\", \"image_path\", \"mole_id\", \"geo_location\", \n",
    "                                   \"label\", \"score\", \"body_location\", \"prior_consultation\", \n",
    "                                   \"pain\", \"itch\"])\n",
    "    else:\n",
    "        df = pd.read_csv(DIARY_CSV)\n",
    "    \n",
    "    entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"image_path\": img_path,\n",
    "        \"mole_id\": mole_id,\n",
    "        \"geo_location\": geo_location,\n",
    "        \"label\": label,\n",
    "        \"score\": float(score),\n",
    "        \"body_location\": body_location,\n",
    "        \"prior_consultation\": prior_consult,\n",
    "        \"pain\": pain,\n",
    "        \"itch\": itch\n",
    "    }\n",
    "\n",
    "    entry_df = pd.DataFrame([entry])\n",
    "    df = pd.concat([df, entry_df], ignore_index=True)\n",
    "    df.to_csv(DIARY_CSV, index=False)\n",
    "    # Debugging: Confirm the entry was saved\n",
    "    st.write(f\"Entry saved for mole ID: {mole_id}\")\n",
    "\n",
    "# Image Preprocessing\n",
    "\n",
    "def preprocess_and_detect_mole(uploaded_file):\n",
    "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
    "    img_rgb = np.array(image)\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    H, S, V = cv2.split(hsv)\n",
    "    h, w = V.shape\n",
    "\n",
    "    # --- 2) Segment original mole via Otsu on Value ---\n",
    "    _, mask = cv2.threshold(V, 0, 255,\n",
    "                            cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "    # --- 3) Randomly distort border ---\n",
    "    kern = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
    "    mask = cv2.dilate(mask, kern, iterations=np.random.randint(1,4))\n",
    "    mask = cv2.erode (mask, kern, iterations=np.random.randint(1,4))\n",
    "\n",
    "    # --- 4) Sprinkle extra dark blotches ---\n",
    "    for _ in range(np.random.randint(5, 15)):\n",
    "        cx = np.random.randint(0, w)\n",
    "        cy = np.random.randint(0, h)\n",
    "        ax = np.random.randint(5, 20)\n",
    "        ay = np.random.randint(5, 20)\n",
    "        ang = np.random.randint(0, 360)\n",
    "        cv2.ellipse(mask, (cx, cy), (ax, ay), ang, 0, 360, 255, -1)\n",
    "\n",
    "    # --- 5) Add variegated noise in V channel inside mask ---\n",
    "    noise = np.random.normal(loc=0, scale=30, size=(h, w)).astype(np.int16)\n",
    "    V2 = V.astype(np.int16) + noise\n",
    "    V2 = np.clip(V2, 0, 255).astype(np.uint8)\n",
    "    V = np.where(mask==255, V2, V)\n",
    "\n",
    "    # --- 6) Random hue shift + saturation boost inside mask ---\n",
    "    hue_shift = np.random.randint(-15, 15)\n",
    "    H2 = (H.astype(np.int16) + hue_shift) % 180\n",
    "    H = np.where(mask==255, H2.astype(np.uint8), H)\n",
    "\n",
    "    sat_boost = np.random.randint(20, 70)\n",
    "    S2 = np.clip(S.astype(np.int16) + sat_boost, 0, 255)\n",
    "    S = np.where(mask==255, S2.astype(np.uint8), S)\n",
    "\n",
    "    # --- 7) Recombine & convert back to RGB ---\n",
    "    hsv_mod = cv2.merge([H, S, V])\n",
    "    rgb_mod = cv2.cvtColor(hsv_mod, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    return Image.fromarray(rgb_mod)\n",
    "\n",
    "\n",
    "# -----Streamlit layout ---- \n",
    "st.title(\"ü©∫ Skin Cancer Recognition Dashboard\")\n",
    "menu = [\"Scan Mole\",\"Chat\",\"Diary\", \"Dataset Explorer\"]\n",
    "choice = st.sidebar.selectbox(\"Navigation\", menu)\n",
    "\n",
    "# --- Initialize Scan a Mole ---\n",
    "\n",
    "if choice == \"Scan Mole\":\n",
    "    st.header(\"üîç Scan a Mole\")\n",
    "    if not classifier:\n",
    "        st.error(\"Missing HF_TOKEN.\")\n",
    "        st.stop()\n",
    "\n",
    "    upload = st.file_uploader(\"Upload a skin image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "    if upload is not None:\n",
    "        # Preprocess the image and detect mole automatically\n",
    "        preprocessed_image = preprocess_and_detect_mole(upload)\n",
    "\n",
    "        st.image(preprocessed_image, caption=\"Preprocessed\", use_container_width=True)\n",
    "\n",
    "    # Collect user inputs\n",
    "    mole = st.text_input(\"Mole ID\")\n",
    "    city = st.text_input(\"Geographic location\")\n",
    "    body = st.selectbox(\n",
    "        \"Body location\",\n",
    "        [\"Face\", \"Scalp\", \"Neck\", \"Chest\", \"Back\", \"Arm\", \"Hand\", \"Leg\", \"Foot\", \"Other\"]\n",
    "    )\n",
    "    prior = st.radio(\"Prior consult?\", [\"Yes\", \"No\"], horizontal=True)\n",
    "    pain = st.radio(\"Pain?\", [\"Yes\", \"No\"], horizontal=True)\n",
    "    itch = st.radio(\"Itch?\", [\"Yes\", \"No\"], horizontal=True)\n",
    "\n",
    "    if st.button(\"Classify\"):\n",
    "        if not mole or not city:\n",
    "            st.error(\"Enter ID and location.\")\n",
    "        else:\n",
    "            # Reset map visibility when new classification occurs\n",
    "            st.session_state.show_map = False\n",
    "\n",
    "            with st.spinner(\"Analyzing...\"):\n",
    "                # Reset file pointer and classify\n",
    "                upload.seek(0)\n",
    "                img = Image.open(upload).convert(\"RGB\")\n",
    "                out = classifier(preprocessed_image)\n",
    "\n",
    "            lbl, scr = out[0][\"label\"], out[0][\"score\"]\n",
    "\n",
    "            # Store label and geo_location in session_state\n",
    "            st.session_state[\"label\"] = lbl\n",
    "            st.session_state[\"score\"] = scr\n",
    "            st.session_state['mole_id'] = mole\n",
    "            st.session_state[\"geo_location\"] = city  # Store geo_location\n",
    "\n",
    "            # Save the classification and user inputs in the DataFrame\n",
    "            save_entry(\n",
    "                img_path=\"path/to/mole/image.jpg\",  # Replace with actual image path\n",
    "                mole_id=mole,\n",
    "                geo_location=city,\n",
    "                label=lbl,\n",
    "                score=scr,\n",
    "                body_location=body,\n",
    "                prior_consult=prior,\n",
    "                pain=pain,\n",
    "                itch=itch\n",
    "            )\n",
    "\n",
    "            st.success(f\"Classification result: {lbl} with score {scr:.4f}\")\n",
    "\n",
    "    # Handle label and recommendation display\n",
    "    if st.session_state.get(\"label\"):\n",
    "        lbl = st.session_state[\"label\"]\n",
    "        score = st.session_state[\"score\"]\n",
    "\n",
    "        # Hardcoded explanations and recommendations\n",
    "        recommendations = {\n",
    "            \"benign_keratosis-like_lesions\": (\n",
    "                \"These are non-cancerous growths often due to sun exposure. \"\n",
    "                \"They typically do not transform into cancer.\",\n",
    "                \"Recommendation: Routine self-monitoring; clinical check every 12 months.\"\n",
    "            ),\n",
    "            \"basal_cell_carcinoma\": (\n",
    "                \"The most common form of skin cancer. It grows slowly and rarely spreads but can damage surrounding tissue.\",\n",
    "                \"Recommendation: See a dermatologist within 2 weeks for evaluation and treatment.\"\n",
    "            ),\n",
    "            \"actinic_keratoses\": (\n",
    "                \"Rough, scaly patches caused by long-term sun exposure. They can progress to squamous cell carcinoma.\",\n",
    "                \"Recommendation: Schedule dermatology visit within 1 month; follow-up every 6 months.\"\n",
    "            ),\n",
    "            \"vascular_lesions\": (\n",
    "                \"Benign growths of blood vessels such as hemangiomas or spider angiomas. \"\n",
    "                \"Usually harmless but monitor changes.\",\n",
    "                \"Recommendation: Self-monitor; clinical review if changes occur or annually.\"\n",
    "            ),\n",
    "            \"melanocytic_Nevi\": (\n",
    "                \"Common moles composed of melanocyte cells. Most are benign but can rarely develop into melanoma.\",\n",
    "                \"Recommendation: Monthly self-exams using the ABCDE rule; dermatology check every 12 months.\"\n",
    "            ),\n",
    "            \"melanoma\": (\n",
    "                \"A serious form of skin cancer that can spread quickly to other organs if not caught early.\",\n",
    "                \"Recommendation: Urgent dermatologist appointment within 1 week; regular follow-up as advised.\"\n",
    "            ),\n",
    "            \"dermatofibroma\": (\n",
    "                \"A benign, firm skin nodule usually caused by minor skin injury. Remains stable over time.\",\n",
    "                \"Recommendation: No immediate treatment needed; check annually or if it changes.\"\n",
    "            )  \n",
    "        }\n",
    "\n",
    "        if lbl in recommendations:\n",
    "            st.subheader(f\"About {lbl.replace('_', ' ').title()}\")\n",
    "            st.write(recommendations[lbl][0])\n",
    "            st.write(recommendations[lbl][1])\n",
    "        else:\n",
    "            st.write(\"No specific information available for this diagnosis.\")\n",
    "\n",
    "    \n",
    "    if st.session_state.get(\"geo_location\"):\n",
    "        loc = geolocator.geocode(st.session_state.get(\"geo_location\"))\n",
    "        if loc:\n",
    "            # Allow user to adjust search radius\n",
    "            radius = st.slider(\n",
    "                \"Search radius (meters)\",\n",
    "                min_value=1000,\n",
    "                max_value=20000,\n",
    "                value=5000,\n",
    "                step=500,\n",
    "                key=\"search_radius\"\n",
    "            )\n",
    "\n",
    "            # Center the button in the layout\n",
    "            cols = st.columns([1, 2, 1])\n",
    "            with cols[1]:\n",
    "                if st.button(\"Recommend Nearby Doctors\", key=\"show_map_btn\"):\n",
    "                    st.session_state.show_map = True\n",
    "\n",
    "            if st.session_state.get(\"show_map\"):\n",
    "                # Initialize map at user's location\n",
    "                m = folium.Map([loc.latitude, loc.longitude], zoom_start=12)\n",
    "                folium.CircleMarker(\n",
    "                    location=[loc.latitude, loc.longitude],\n",
    "                    radius=8,\n",
    "                    popup=\"You\",\n",
    "                    weight=1,\n",
    "                    fill=True\n",
    "                ).add_to(m)\n",
    "\n",
    "                # Use MarkerCluster for better visualization\n",
    "                from folium.plugins import MarkerCluster\n",
    "                cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "                # Query Overpass API for nearby clinics/doctors\n",
    "                resp = requests.post(\n",
    "                    \"https://overpass-api.de/api/interpreter\",\n",
    "                    data={\n",
    "                        \"data\": (\n",
    "                            f\"[out:json];node(around:{radius},{loc.latitude},{loc.longitude})\"\n",
    "                            \"[~\\\"^(amenity|healthcare)$\\\"~\\\"clinic|doctors\\\"];out;\"\n",
    "                        )\n",
    "                    }\n",
    "                )\n",
    "                elements = resp.json().get(\"elements\", [])\n",
    "\n",
    "                if elements:\n",
    "                    for el in elements:\n",
    "                        tags = el.get(\"tags\", {})\n",
    "                        lat = el.get(\"lat\") or el.get(\"center\", {}).get(\"lat\")\n",
    "                        lon = el.get(\"lon\") or el.get(\"center\", {}).get(\"lon\")\n",
    "                        name = tags.get(\"name\", \"Clinic/Doctor\")\n",
    "                        folium.Marker(\n",
    "                            location=[lat, lon],\n",
    "                            popup=name,\n",
    "                            icon=folium.Icon(icon=\"plus-sign\", prefix=\"glyphicon\")\n",
    "                        ).add_to(cluster)\n",
    "                else:\n",
    "                    st.warning(\"No clinics or doctors found in this radius.\")\n",
    "\n",
    "                # Display the map\n",
    "                st.markdown(\"### Nearby Clinics & Doctors\")\n",
    "                st_folium(m, width=\"100%\", height=500)\n",
    "\n",
    "\n",
    "                    \n",
    "# --- Chat ---\n",
    "elif choice == \"Chat\":\n",
    "    st.header(\"üí¨ Follow-Up Chat\")\n",
    "    if not st.session_state['label']:\n",
    "        st.info(\"Please perform a scan first in the 'Scan Mole' tab.\")\n",
    "    else:\n",
    "        lbl = st.session_state['label']\n",
    "        scr = st.session_state['score']\n",
    "        mid = st.session_state['mole_id']\n",
    "        gloc = st.session_state['geo_location']\n",
    "        st.markdown(f\"**Context:** prediction for **{mid}** at **{gloc}** is **{lbl}** (confidence {scr:.2f}).\")\n",
    "\n",
    "        # New user message comes first for immediate loop\n",
    "        user_q = st.chat_input(\"Ask a follow-up question:\", key=\"chat_input\")\n",
    "        if user_q and explainer:\n",
    "            st.session_state['chat_history'].append({'role':'user','content':user_q})\n",
    "            system_p = \"You are a dermatology assistant. Provide concise medical advice without clarifying questions.\"\n",
    "            tpl = (\n",
    "                f\"{system_p}\\nContext: prediction is {lbl} with confidence {scr:.2f}.\\n\"\n",
    "                f\"User: {user_q}\\nAssistant:\"\n",
    "            )\n",
    "            with st.spinner(\"Generating response...\"):\n",
    "                reply = explainer(tpl)[0]['generated_text']\n",
    "            st.session_state['chat_history'].append({'role':'assistant','content':reply})\n",
    "\n",
    "        # Display the updated chat history\n",
    "        for msg in st.session_state['chat_history']:\n",
    "            prefix = 'You' if msg['role']=='user' else 'AI'\n",
    "            st.markdown(f\"**{prefix}:** {msg['content']}\")\n",
    "\n",
    "# --- Diary Page ---\n",
    "elif choice == \"Diary\":\n",
    "    st.header(\"üìñ Skin Cancer Diary\")\n",
    "    df = pd.read_csv(DIARY_CSV)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    if df.empty:\n",
    "        st.info(\"No diary entries yet.\")\n",
    "    else:\n",
    "        mole_ids = sorted(df['mole_id'].unique())\n",
    "        sel = st.selectbox(\"Select Mole to View\", ['All'] + mole_ids, key=\"diary_sel\")\n",
    "        if sel == 'All':\n",
    "            # Display moles in columns (max 3 per row)\n",
    "            chunks = [mole_ids[i:i+3] for i in range(0, len(mole_ids), 3)]\n",
    "            for group in chunks:\n",
    "                cols = st.columns(len(group))\n",
    "                for col, mid in zip(cols, group):\n",
    "                    with col:\n",
    "                        st.subheader(mid)\n",
    "                        entries = df[df['mole_id'] == mid].sort_values('timestamp')\n",
    "                        # Show image timeline\n",
    "                        for _, row in entries.iterrows():\n",
    "                            if os.path.exists(row['image_path']):\n",
    "                                st.image(\n",
    "                                    row['image_path'],\n",
    "                                    width=150,\n",
    "                                    caption=f\"{row['timestamp'].strftime('%Y-%m-%d')} ‚Äî {row['score']:.2f}\"\n",
    "                                )\n",
    "                        st.write(f\"Total scans: {len(entries)}\")\n",
    "        else:\n",
    "            # Detailed view for a single mole\n",
    "            entries = df[df['mole_id'] == sel].sort_values('timestamp')\n",
    "            if entries.empty:\n",
    "                st.warning(f\"No entries for {sel}.\")\n",
    "            else:\n",
    "                # Score over time\n",
    "                st.line_chart(entries.set_index('timestamp')['score'])\n",
    "\n",
    "                # Organized image timeline in 4 columns\n",
    "                st.markdown(\"#### Image Timeline\")\n",
    "                chunks = [entries.iloc[i:i+4] for i in range(0, len(entries), 4)]\n",
    "                for chunk in chunks:\n",
    "                    cols = st.columns(4)\n",
    "                    for col, (_, row) in zip(cols, chunk.iterrows()):\n",
    "                        with col:\n",
    "                            if os.path.exists(row['image_path']):\n",
    "                                st.image(\n",
    "                                    row['image_path'],\n",
    "                                    width=200,\n",
    "                                    caption=(\n",
    "                                        f\"{row['timestamp'].strftime('%Y-%m-%d %H:%M')} ‚Äî \"\n",
    "                                        f\"Score: {row['score']:.2f}\"\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                # Details table\n",
    "                st.markdown(\"#### Details\")\n",
    "                st.dataframe(\n",
    "                    entries[\n",
    "                        ['timestamp','geo_location','label','score',\n",
    "                         'body_location','prior_consultation','pain','itch']\n",
    "                    ]\n",
    "                    .rename(columns={\n",
    "                        'timestamp':'Time','geo_location':'Location',\n",
    "                        'label':'Diagnosis','score':'Confidence',\n",
    "                        'body_location':'Body Part','prior_consultation':'Prior Consult',\n",
    "                        'pain':'Pain','itch':'Itch'\n",
    "                    })\n",
    "                    .sort_values('Time', ascending=False)\n",
    "                )\n",
    "\n",
    "else:\n",
    "    st.header(\"üìÇ Dataset Explorer\")\n",
    "    st.write(\"Preview images from the Harvard Skin Cancer Dataset\")\n",
    "\n",
    "    # pick up to 15 image files\n",
    "    image_files = [\n",
    "    f for f in os.listdir(DATA_DIR)\n",
    "    if os.path.isfile(os.path.join(DATA_DIR, f))\n",
    "    and f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ][:15]\n",
    "\n",
    "    for i in range(0, len(image_files), 3):\n",
    "        cols = st.columns(3)\n",
    "        for col, fn in zip(cols, image_files[i : i + 3]):\n",
    "            path = os.path.join(DATA_DIR, fn)\n",
    "            img = Image.open(path)\n",
    "            col.image(img, use_container_width=True)\n",
    "            col.caption(fn)\n",
    "\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.write(\"Dataset powered by Harvard Dataverse [DBW86T]\")\n",
    "st.sidebar.write(f\"Model: {MODEL_NAME}\")\n",
    "st.sidebar.write(f\"LLM: {LLM_NAME}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    st.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecadd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
