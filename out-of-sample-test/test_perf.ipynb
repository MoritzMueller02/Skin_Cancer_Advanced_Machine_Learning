{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec7fa21",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\benbu\\anaconda3\\lib\\site-packages (2.3.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\benbu\\anaconda3\\lib\\site-packages (0.18.0+cpu)\n",
      "Requirement already satisfied: pillow in c:\\users\\benbu\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\benbu\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\benbu\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\benbu\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\benbu\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\benbu\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/39.4 MB 24.1 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.8/39.4 MB 18.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.8/39.4 MB 19.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.0/39.4 MB 21.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 5.2/39.4 MB 22.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.3/39.4 MB 21.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.0/39.4 MB 20.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.0/39.4 MB 21.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 9.4/39.4 MB 22.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 10.8/39.4 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 11.9/39.4 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 13.1/39.4 MB 25.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.3/39.4 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 15.2/39.4 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 16.3/39.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 17.2/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.3/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 19.4/39.4 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.8/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.1/39.4 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 23.4/39.4 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.7/39.4 MB 25.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.0/39.4 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.4/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 28.3/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.5/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.8/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.1/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.6/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.7/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.8/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.9/39.4 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.2/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.9/10.4 MB 29.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.3/10.4 MB 36.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.6/10.4 MB 28.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.8/10.4 MB 28.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.2/10.4 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 27.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.4 MB 28.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.4 MB 28.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.4 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 20.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "   ---------------------------------------- 0.0/484.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 484.2/484.2 kB 15.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 308.9/308.9 kB 19.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.4/2.4 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 15.5 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, opencv-python-headless, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.31.2 opencv-python-headless-4.11.0.86 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python-headless transformers torch torchvision pillow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8174be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# First, install dependencies in your local environment (run in terminal, not in the notebook):\n",
    "# pip install transformers torch torchvision pillow scikit-learn opencv-python-headless\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. Load the pretrained HF model and processor\n",
    "model_name = \"Anwarkh1/Skin_Cancer-Image_Classification\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"image-classification\", model=model, feature_extractor=processor)\n",
    "\n",
    "# 2. Define your preprocessing function\n",
    "def preprocess_and_detect_mole(uploaded_file):\n",
    "    image = Image.open(uploaded_file)\n",
    "    image_rgb = np.array(image.convert('RGB'))\n",
    "    gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, thresh = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    mask = np.zeros(gray_image.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped_image = image_rgb[y:y+h, x:x+w]\n",
    "    cropped_image_pil = Image.fromarray(cropped_image)\n",
    "    return cropped_image_pil\n",
    "\n",
    "\n",
    "# 3. Load your metadata CSV\n",
    "metadata = pd.read_csv(\"challenge-2016-test_metadata_2025-05-14.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd6a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 379 entries, 0 to 378\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   isic_id                 379 non-null    object \n",
      " 1   attribution             379 non-null    object \n",
      " 2   copyright_license       379 non-null    object \n",
      " 3   age_approx              320 non-null    float64\n",
      " 4   anatom_site_general     299 non-null    object \n",
      " 5   anatom_site_special     5 non-null      object \n",
      " 6   benign_malignant        378 non-null    object \n",
      " 7   clin_size_long_diam_mm  202 non-null    float64\n",
      " 8   concomitant_biopsy      379 non-null    bool   \n",
      " 9   diagnosis_1             379 non-null    object \n",
      " 10  diagnosis_2             376 non-null    object \n",
      " 11  diagnosis_3             375 non-null    object \n",
      " 12  diagnosis_4             167 non-null    object \n",
      " 13  diagnosis_5             57 non-null     object \n",
      " 14  diagnosis_confirm_type  282 non-null    object \n",
      " 15  family_hx_mm            198 non-null    object \n",
      " 16  image_type              379 non-null    object \n",
      " 17  melanocytic             374 non-null    object \n",
      " 18  personal_hx_mm          202 non-null    object \n",
      " 19  sex                     322 non-null    object \n",
      "dtypes: bool(1), float64(2), object(17)\n",
      "memory usage: 56.8+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50f932",
   "metadata": {},
   "source": [
    "Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b08b979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Clean up the ground-truth column\n",
    "#   - drop any rows where 'benign_malignant' is blank/NaN\n",
    "#   - normalize everything to lowercase strings\n",
    "metadata = metadata.dropna(subset=[\"benign_malignant\"]).copy()\n",
    "metadata[\"benign_malignant\"] = metadata[\"benign_malignant\"].astype(str).str.lower()\n",
    "\n",
    "# (Optional) If you want to be extra safe, filter to only the two labels you expect:\n",
    "metadata = metadata[\n",
    "    metadata[\"benign_malignant\"].isin([\"benign\", \"malignant\"])\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411b423",
   "metadata": {},
   "source": [
    "Inspect prediction labels of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11c5b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model id2label: {0: 'benign_keratosis-like_lesions', 1: 'basal_cell_carcinoma', 2: 'actinic_keratoses', 3: 'vascular_lesions', 4: 'melanocytic_Nevi', 5: 'melanoma', 6: 'dermatofibroma'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect model’s label mapping\n",
    "id2label = model.config.id2label\n",
    "print(\"Model id2label:\", id2label)\n",
    "# e.g.: {0: 'benign', 1: 'malignant'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f6208",
   "metadata": {},
   "source": [
    "## Test performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16c63c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7526595744680851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.89      0.80      0.84       303\n",
      "   malignant       0.40      0.58      0.47        73\n",
      "\n",
      "    accuracy                           0.75       376\n",
      "   macro avg       0.64      0.69      0.66       376\n",
      "weighted avg       0.79      0.75      0.77       376\n",
      "\n",
      "[[241  62]\n",
      " [ 31  42]]\n"
     ]
    }
   ],
   "source": [
    "# 1) Define a mapping from the model’s 7 classes to your 2 classes:\n",
    "fine_to_binary = {\n",
    "    \"benign_keratosis-like_lesions\": \"benign\",\n",
    "    \"basal_cell_carcinoma\":          \"malignant\",\n",
    "    \"actinic_keratoses\":             \"benign\",\n",
    "    \"vascular_lesions\":              \"benign\",\n",
    "    \"melanocytic_Nevi\":              \"benign\",\n",
    "    \"melanoma\":                      \"malignant\",\n",
    "    \"dermatofibroma\":                \"benign\",\n",
    "}\n",
    "\n",
    "# 2) Run your batch (or looped) inference to get `results`:\n",
    "# (Either as a list-of-lists from pipeline or inside your loop.)\n",
    "# Here’s the batch example again:\n",
    "imgs, true_labels = [], []\n",
    "for _, row in metadata.iterrows():\n",
    "    path = os.path.join(\"ISIC-images\", f\"{row['isic_id']}.jpg\")\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "    imgs.append(preprocess_and_detect_mole(path))\n",
    "    true_labels.append(row[\"benign_malignant\"].lower())\n",
    "\n",
    "results = classifier(imgs, batch_size=16)\n",
    "\n",
    "# 3) Collapse the predicted labels:\n",
    "pred_labels = [\n",
    "    fine_to_binary[result[0][\"label\"]]  # e.g. \"melanoma\" → \"malignant\"\n",
    "    for result in results\n",
    "]\n",
    "\n",
    "# 4) Now `true_labels` vs `pred_labels` are both in {\"benign\",\"malignant\"}:\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, pred_labels))\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "print(confusion_matrix(true_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdaf876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241,  62],\n",
       "       [ 31,  42]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_labels, pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
